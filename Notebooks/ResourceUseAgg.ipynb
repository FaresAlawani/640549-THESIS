{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating and visualizing resource usage of all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The resource use readings were manually added to a csv file after each run and then loaded here as you see. \n",
    "##### BERT+GPT was also manually created by simply adding the additional GPT call readings to the readings of BERTopic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT = pd.read_csv('Aggregated_Execution_Data.csv')\n",
    "order = [1, 0, 2, 3, 4]\n",
    "BERT = BERT.reindex(order).reset_index(drop=True)\n",
    "BERT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT = pd.read_csv('New_Execution_Data.csv')\n",
    "GPT.loc[0] = [\"R1\", 246.24772490002215, 0.010311008968837672,  1.0494308471679688]\n",
    "GPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERTGPT\n",
    "BERTGPT = {\n",
    "    \"Run\": [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"],\n",
    "    \"Total Execution Time (s)\": [3083.537871, 2999.055829, 2315.157078, 3111.906329, 3176.367225],\n",
    "    \"Total CPU Usage (%)\": [98.451443, 97.335971, 96.903467, 98.851763, 71.373458],\n",
    "    \"Total Peak Memory Usage (MB)\": [692.627967, 667.752795, 593.163465, 684.064885, 628.145993]\n",
    "}\n",
    "\n",
    "BERTGPT = pd.DataFrame(BERT)\n",
    "\n",
    "#\n",
    "execution_times = [23.94018610008061, 28.39324160013348, 25.714675500057638, 24.874196600168943, 31.00697570014745]\n",
    "cpu_usages = [0.016316706911425585, 0.044712444879630504, 0.049369911356538586, 0.031408049576752715, 0.047242393588002654]\n",
    "peak_memory_usages = [1.4425983428955078, 0.3029136657714844, 0.2512035369873047, 0.23195838928222656, 0.28528499603271484]\n",
    "\n",
    "# \n",
    "BERTGPT[\"Total Execution Time (s)\"] += execution_times\n",
    "BERTGPT[\"Total CPU Usage (%)\"] += cpu_usages\n",
    "BERTGPT[\"Total Peak Memory Usage (MB)\"] += peak_memory_usages\n",
    "\n",
    "#\n",
    "BERTGPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "#\n",
    "width = 0.2  \n",
    "positions = [0, 1, 2, 3, 4]\n",
    "#\n",
    "ax.bar([p - width for p in positions], BERT[\"Total Execution Time (s)\"], width=width, color='blue', alpha=0.7, label=\"BERTopic Execution Time (s)\")\n",
    "ax.bar(positions, BERTGPT[\"Total Execution Time (s)\"], width=width, color='orange', alpha=0.7, label=\"BERT+GPT Execution Time (s)\")\n",
    "ax.bar([p + width for p in positions], GPT[\"Execution Time (s)\"], width=width, color='red', alpha=0.7, label=\"GPT Execution Time (s)\")\n",
    "#\n",
    "ax.set_ylabel(\"Execution Time (s)\")\n",
    "ax.set_title(\"Comparison of Execution Time\")\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(BERT[\"Run\"])\n",
    "#\n",
    "ax.legend(fontsize='small')\n",
    "#\n",
    "plt.xlim(-0.5, len(positions) - 0.5)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(BERT.index, BERT[\"Total CPU Usage (%)\"], marker='o', linestyle='-', color='blue', label='BERT Total CPU Usage (%)')\n",
    "plt.plot(BERTGPT.index, BERT[\"Total CPU Usage (%)\"], marker='o', linestyle='--', color='orange', label='BERT+GPT Total CPU Usage (%)')\n",
    "plt.plot(GPT.index, GPT[\"CPU Usage (%)\"], marker='o', linestyle='-', color='red', label='GPT CPU Usage (%)')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"CPU Usage (%)\")\n",
    "plt.title(\"Comparison of CPU Usage (Logarithmic Scale)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "GPT = {\n",
    "    \"Run\": [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"],\n",
    "    \"Total Peak Memory Usage (MB)\": [1.049431, 0.802281, 0.531520, 0.591152, 0.774975]\n",
    "}\n",
    "\n",
    "#\n",
    "BERT = {\n",
    "    \"Run\": [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"],\n",
    "    \"Total Peak Memory Usage (MB)\": [692.627967, 667.752795, 593.163465, 684.064885, 628.145993]\n",
    "}\n",
    "\n",
    "# \n",
    "BERTGPT = {\n",
    "    \"Run\": [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"],\n",
    "    \"Total Peak Memory Usage (MB)\": [695.513164, 668.358623, 593.665873, 684.528802, 628.716563]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(GPT)\n",
    "df2 = pd.DataFrame(BERT)\n",
    "df3 = pd.DataFrame(BERTGPT)\n",
    "\n",
    "# \n",
    "df1['Dataset'] = 'GPT'\n",
    "df2['Dataset'] = 'BERT'\n",
    "df3['Dataset'] = 'BERT+GPT'\n",
    "combined_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# \n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "# \n",
    "bar_width = 0.2\n",
    "index = np.arange(len(df1))\n",
    "bar1 = ax.bar(index - bar_width, df1[\"Total Peak Memory Usage (MB)\"], bar_width, label='GPT')\n",
    "bar2 = ax.bar(index, df2[\"Total Peak Memory Usage (MB)\"], bar_width, label='BERT')\n",
    "bar3 = ax.bar(index + bar_width, df3[\"Total Peak Memory Usage (MB)\"], bar_width, label='BERT+GPT')\n",
    "\n",
    "###############\n",
    "def annotate_bars(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 5),  # 5 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=8)  # Smaller font size\n",
    "\n",
    "annotate_bars(bar1)\n",
    "annotate_bars(bar2)\n",
    "annotate_bars(bar3)\n",
    "\n",
    "####################\n",
    "ax.set_xlabel(\"Run\")\n",
    "ax.set_ylabel(\"Total Peak Memory Usage (MB)\")\n",
    "ax.set_title(\"Comparison of Peak Memory Usage (MB) Between All Models\")\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(df1[\"Run\"])\n",
    "ax.legend()\n",
    "\n",
    "#\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
