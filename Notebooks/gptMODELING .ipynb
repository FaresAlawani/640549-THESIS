{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing + GPT MODELING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import DutchStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import tiktoken\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import psutil\n",
    "import tracemalloc\n",
    "from bertopic import BERTopic\n",
    "import nbformat\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import umap as UMAP\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='xxxxxxxxxxxxxxx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load the data \n",
    "r1 = pd.read_csv('XXXXX', sep=';')\n",
    "r2 = pd.read_csv('XXXXX', sep=';')\n",
    "r3 = pd.read_csv(\"XXXXX\", sep=';')\n",
    "r4 = pd.read_csv('XXXXXX', sep=';')\n",
    "r5 = pd.read_csv(\"XXXXXX.csv\", sep=';')\n",
    "\n",
    "#Merge positive and negative together into review column\n",
    "r3['Review'] = r3['Negatief'].fillna(r3['Positief'])\n",
    "r4['Review'] = r4['Negatief'].fillna(r4['Positief'])\n",
    "r5['Review'] = r5['Negatief'].fillna(r5['Positief'])\n",
    "\n",
    "##make dataframes with only review columns \n",
    "r1 = r1[['Review']]\n",
    "r2 = r2[['Review']]\n",
    "r3 = r3[['Review']]\n",
    "r4 = r4[['Review']]\n",
    "r5 = r5[['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####sample and clean reviews\n",
    "def cleanSample_reviews(df, review_col, sample_size=20000):\n",
    "    \n",
    "    # Remove NA values\n",
    "    df_cleaned = df.dropna(subset=[review_col])\n",
    "    \n",
    "    # Randomly sample reviews\n",
    "    df_sampled = df_cleaned.sample(n=sample_size, random_state=5, replace=True) if len(df_cleaned) > sample_size else df_cleaned\n",
    "    \n",
    "    return df_sampled\n",
    "#####\n",
    "r1 = cleanSample_reviews(r1, 'Review')\n",
    "r2 = cleanSample_reviews(r2, 'Review')\n",
    "r3 = cleanSample_reviews(r3, 'Review')\n",
    "r4 = cleanSample_reviews(r4, 'Review')\n",
    "r5 = cleanSample_reviews(r5, 'Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####PREPROCESSING FUNCTION \n",
    "\n",
    "def preprocess_text(text, use_stemming=True):\n",
    "    # 1. Tokenize the text\n",
    "    tokens = word_tokenize(text, language='dutch')\n",
    "    \n",
    "    # 2. Remove stopwords\n",
    "    stop_words = set(stopwords.words('dutch'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # 3. Remove numbers and URLs\n",
    "    tokens = [re.sub(r'\\b\\d+\\b', '', word) for word in tokens]  # Remove numbers\n",
    "    tokens = [re.sub(r'http\\S+|www\\S+|https\\S+', '', word) for word in tokens]  # Remove URLs\n",
    "    tokens = [word for word in tokens if word]  # Remove empty strings after removal\n",
    "    \n",
    "    # 4. Normalize the text to lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # 5. Perform stemming or lemmatization\n",
    "    if use_stemming:\n",
    "        stemmer = SnowballStemmer('dutch')\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    else:\n",
    "        lemmatizer = WordNetLemmatizer()  # WordNetLemmatizer doesn't support Dutch, so custom implementation needed\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply preprocessing on the reviews \n",
    "r1['P_review'] = r1['Review'].apply(preprocess_text)\n",
    "r2['P_review'] = r2['Review'].apply(preprocess_text)\n",
    "r3['P_review'] = r3['Review'].apply(preprocess_text)\n",
    "r4['P_review'] = r4['Review'].apply(preprocess_text)\n",
    "r5['P_review'] = r5['Review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5.to_csv('R5FINALPROCESS.csv', index=False)\n",
    "r4.to_csv('R4FINALPROCESS.csv', index=False)\n",
    "r3.to_csv('R3FINALPROCESS.csv', index=False)\n",
    "r2.to_csv('R2FINALPROCESS.csv', index=False)\n",
    "r1.to_csv('R1FINALPROCESS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count per review distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('R1FINALPROCESS.csv')\n",
    "r2 = pd.read_csv('R2FINALPROCESS.csv')\n",
    "r3 = pd.read_csv('R3FINALPROCESS.csv')\n",
    "r4 = pd.read_csv('R4FINALPROCESS.csv')\n",
    "r5 = pd.read_csv('R5FINALPROCESS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = pd.concat([r1, r2, r3, r4, r5])\n",
    "# Apply preprocessing on the reviews\n",
    "#all_reviews['P_review'] = all_reviews['Review'].apply(preprocess_text)\n",
    "all_reviews['Review'] = all_reviews['Review'].fillna('').astype(str)\n",
    "all_reviews['P_review'] = all_reviews['P_review'].fillna('').astype(str)\n",
    "# Calculate the original and processed word counts\n",
    "all_reviews['original_word_count'] = all_reviews['Review'].apply(lambda x: len(x.split()))\n",
    "all_reviews['processed_word_count'] = all_reviews['P_review'].apply(lambda x: len(x.split()))\n",
    "max_word_count = max(all_reviews['original_word_count'].max(), all_reviews['processed_word_count'].max())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Overlay histograms with edge color for better definition\n",
    "plt.hist(all_reviews['original_word_count'], bins=range(0, 80), color='blue', alpha=0.5, edgecolor='black', label='Original', linewidth=1.2)\n",
    "plt.hist(all_reviews['processed_word_count'], bins=range(0, 80), color='green', alpha=0.5, edgecolor='black', label='Processed', linewidth=1.2)\n",
    "\n",
    "# Adding labels, title, and grid\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Word Counts (Original vs Processed)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming r1, r2, r3, r4, and r5 are your DataFrames\n",
    "all_reviews = pd.concat([r1, r2, r3, r4, r5])\n",
    "\n",
    "# Apply preprocessing on the reviews\n",
    "# all_reviews['P_review'] = all_reviews['Review'].apply(preprocess_text)\n",
    "all_reviews['Review'] = all_reviews['Review'].fillna('').astype(str)\n",
    "all_reviews['P_review'] = all_reviews['P_review'].fillna('').astype(str)\n",
    "\n",
    "# Calculate the original and processed word counts\n",
    "all_reviews['original_word_count'] = all_reviews['Review'].apply(lambda x: len(x.split()))\n",
    "all_reviews['processed_word_count'] = all_reviews['P_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Combine all text in the 'Review' column into a single string\n",
    "original_text = ' '.join(all_reviews['Review'])\n",
    "\n",
    "# Combine all text in the 'P_review' column into a single string\n",
    "processed_text = ' '.join(all_reviews['P_review'])\n",
    "\n",
    "# Generate word cloud for original text\n",
    "wordcloud_original = WordCloud(width=800, height=400, background_color='white').generate(original_text)\n",
    "\n",
    "# Generate word cloud for processed text\n",
    "wordcloud_processed = WordCloud(width=800, height=400, background_color='white').generate(processed_text)\n",
    "\n",
    "# Plotting the word cloud for original text\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud_original, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Original Text')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the word cloud for processed text\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud_processed, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Processed Text')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud for all reviews; before and after "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling using GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split text into chunks based on the model's token limit\n",
    "def split_into_chunks(text, max_tokens=16000):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for word in words:\n",
    "        word_tokens = len(encoding.encode(word))\n",
    "        if current_tokens + word_tokens <= max_tokens:\n",
    "            current_chunk.append(word)\n",
    "            current_tokens += word_tokens\n",
    "        else:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_tokens = word_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Topic modeling function using GPT-3.5-turbo\n",
    "def topic_modeling(example):\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in topic modeling customer review data. I am going to provide you with a dataset of customer reviews. Please analyze this data and return a detailed mapping of the most recurring topics. For each topic, list the most associated keywords that represent it. Ensure that the topics and keywords are clear, distinct, and capture the essence of the reviews.\"  \n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{example}\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "  \n",
    "  try:\n",
    "    return response.choices[0].message.content\n",
    "  except (KeyError, IndexError) as e:\n",
    "    return \"Error: Unable to process the response.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Helper function to process each review set\n",
    "def process_reviews(reviews, index):\n",
    "    text_data = reviews['P_review'].tolist()\n",
    "    markdown_block = ', '.join(text_data)\n",
    "    chunks = split_into_chunks(markdown_block, max_tokens=16000)\n",
    "\n",
    "    # Get the current process\n",
    "    process = psutil.Process()\n",
    "\n",
    "    # Measure initial CPU times and memory usage\n",
    "    cpu_times_before = process.cpu_times()\n",
    "    memory_usage_before = process.memory_info().rss\n",
    "\n",
    "    # Start measuring peak memory usage\n",
    "    tracemalloc.start()\n",
    "\n",
    "    # Measure start time\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Apply topic modeling to each chunk\n",
    "    results = [topic_modeling(chunk) for chunk in chunks]\n",
    "\n",
    "    # Measure end time\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    # Measure final memory usage\n",
    "    memory_usage_after = process.memory_info().rss\n",
    "\n",
    "    # Stop measuring peak memory usage and get the result\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    # Measure final CPU times\n",
    "    cpu_times_after = process.cpu_times()\n",
    "\n",
    "    # Calculate execution time\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Calculate CPU usage\n",
    "    user_time = cpu_times_after.user - cpu_times_before.user\n",
    "    system_time = cpu_times_after.system - cpu_times_before.system\n",
    "    cpu_usage = ((user_time + system_time) / execution_time) * 100 / psutil.cpu_count()\n",
    "\n",
    "    # Calculate memory usage difference\n",
    "    memory_usage_difference = (memory_usage_after - memory_usage_before) / (1024 ** 2)  # Convert bytes to MB\n",
    "\n",
    "    # Calculate peak memory usage\n",
    "    memory_usage_peak = peak / (1024 ** 2)  # Convert bytes to MB\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Execution time for r{index}: {execution_time} seconds\")\n",
    "    print(f\"CPU usage during execution for r{index}: {cpu_usage}%\")\n",
    "    print(f\"Peak memory usage during execution for r{index}: {memory_usage_peak} MB\")\n",
    "    print(f\"Memory usage difference during execution for r{index}: {memory_usage_difference} MB\")\n",
    "\n",
    "     ###Create DataFrame and save to HTML\n",
    "    df = pd.DataFrame(results, columns=['topics'])\n",
    "    df.to_html(f'retailer{index}.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process reviews for r1\n",
    "process_reviews(r1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process reviews for r2\n",
    "process_reviews(r2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Process reviews for r3\n",
    "process_reviews(r3, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process reviews for r4\n",
    "process_reviews(r4, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process reviews for r5\n",
    "process_reviews(r5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
